{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Crossview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_channels, hidden_dims, output_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, hidden_dims, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dims, hidden_dims * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_dims * 2 * (image_size // 4) * (image_size // 4), output_dims),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        phi = self.encoder(x)\n",
    "        return phi\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, image_channels, image_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dims, hidden_dims * 2 * (image_size // 4) * (image_size // 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (hidden_dims * 2, image_size // 4, image_size // 4)),\n",
    "            nn.ConvTranspose2d(hidden_dims * 2, hidden_dims, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(hidden_dims, image_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Assuming the input images are normalized to [0,1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example instantiation\n",
    "image_channels = 3  # For RGB images\n",
    "image_size = 64  # Assuming 64x64 images\n",
    "hidden_dims = 64  # Hidden dimensions\n",
    "output_dims = 100  # Size of phi, adjust as per your requirement\n",
    "\n",
    "encoder = Encoder(image_channels, hidden_dims, output_dims)\n",
    "decoder = Decoder(output_dims, hidden_dims, image_channels, image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataLoader for your dataset\n",
    "for epoch in range(num_epochs):\n",
    "    for img, _ in dataloader:\n",
    "        # Normalize images to [0,1]\n",
    "        img = img / 255.0\n",
    "        \n",
    "        phi = encoder(img)\n",
    "        recon_img = decoder(phi)\n",
    "        \n",
    "        loss = ((img - recon_img)**2).mean()  # Mean Squared Error Loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
